<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Connecting to a live stream  Reference</title>
    <link rel="stylesheet" type="text/css" href="css/jazzy.css" />
    <link rel="stylesheet" type="text/css" href="css/highlight.css" />
    <meta charset='utf-8'>
    <script src="js/jquery.min.js" defer></script>
    <script src="js/jazzy.js" defer></script>
    
    <script src="js/lunr.min.js" defer></script>
    <script src="js/typeahead.jquery.js" defer></script>
    <script src="js/jazzy.search.js" defer></script>
  </head>
  <body>
    <a title="Connecting to a live stream  Reference"></a>
    <header>
      <div class="content-wrapper">
        <p><a href="index.html">MycrocastSDK Docs</a> (71% documented)</p>
        <div class="header-right">
          <form role="search" action="search.json">
            <input type="text" placeholder="Search documentation" data-typeahead>
          </form>
        </div>
      </div>
    </header>
    <div class="content-wrapper">
      <p id="breadcrumbs">
        <a href="index.html">MycrocastSDK Reference</a>
        <img id="carat" src="img/carat.png" alt=""/>
        Connecting to a live stream  Reference
      </p>
    </div>
    <div class="content-wrapper">
      <nav class="sidebar">
        <ul class="nav-groups">
          <li class="nav-group-name">
            <a href="Documentation.html">Documentation</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="overview.html">Overview</a>
              </li>
              <li class="nav-group-task">
                <a href="getting-started.html">Getting started</a>
              </li>
              <li class="nav-group-task">
                <a href="connecting-to-a-live-stream.html">Connecting to a live stream</a>
              </li>
              <li class="nav-group-task">
                <a href="what-is-a-livestream.html">What is a LiveStream</a>
              </li>
              <li class="nav-group-task">
                <a href="mycrocast---entry.html">Mycrocast - Entry</a>
              </li>
              <li class="nav-group-task">
                <a href="advertisement.html">Advertisement</a>
              </li>
              <li class="nav-group-task">
                <a href="how-to-chat.html">How to Chat</a>
              </li>
              <li class="nav-group-task">
                <a href="errors.html">Errors</a>
              </li>
            </ul>
          </li>
          <li class="nav-group-name">
            <a href="Example.html">Example</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="example-app-overview.html">Example App Overview</a>
              </li>
              <li class="nav-group-task">
                <a href="example-app--audiosession---handling-a-stream.html">Example App  AudioSession - Handling a Stream</a>
              </li>
              <li class="nav-group-task">
                <a href="example-app-playing-the-audio.html">Example App playing the audio</a>
              </li>
              <li class="nav-group-task">
                <a href="example-app-livestreamcell.html">Example App LiveStreamCell</a>
              </li>
              <li class="nav-group-task">
                <a href="example-app---advertisementbanner.html">Example App - AdvertisementBanner</a>
              </li>
              <li class="nav-group-task">
                <a href="example-app---streamerview.html">Example App - StreamerView</a>
              </li>
              <li class="nav-group-task">
                <a href="example-app---chat.html">Example App - Chat</a>
              </li>
              <li class="nav-group-task">
                <a href="example-app-viewcontroller.html">Example App ViewController</a>
              </li>
            </ul>
          </li>
          <li class="nav-group-name">
            <a href="Other%20Classes.html">Other Classes</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="Other%20Classes.html#/s:12MycrocastSDK18AudioPackageBufferC">AudioPackageBuffer</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/DelayTimeContainer.html">DelayTimeContainer</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/LiveScoringStream.html">LiveScoringStream</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/LiveStream.html">LiveStream</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Mycrocast.html">Mycrocast</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/MycrocastAdvertisement.html">MycrocastAdvertisement</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/MycrocastAssetProvider.html">MycrocastAssetProvider</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/MycrocastError.html">MycrocastError</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Streamer.html">Streamer</a>
              </li>
            </ul>
          </li>
          <li class="nav-group-name">
            <a href="Other%20Enums.html">Other Enumerations</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="Enums/ChatStatus.html">ChatStatus</a>
              </li>
              <li class="nav-group-task">
                <a href="Enums/ErrorType.html">ErrorType</a>
              </li>
              <li class="nav-group-task">
                <a href="Enums/RatingError.html">RatingError</a>
              </li>
              <li class="nav-group-task">
                <a href="Enums/ReportReason.html">ReportReason</a>
              </li>
              <li class="nav-group-task">
                <a href="Enums/Sender.html">Sender</a>
              </li>
              <li class="nav-group-task">
                <a href="Enums/SessionState.html">SessionState</a>
              </li>
              <li class="nav-group-task">
                <a href="Enums/UserStreamRating.html">UserStreamRating</a>
              </li>
            </ul>
          </li>
          <li class="nav-group-name">
            <a href="Other%20Extensions.html">Other Extensions</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="Other%20Extensions.html#/AppKit">AppKit</a>
              </li>
              <li class="nav-group-task">
                <a href="Other%20Extensions.html#/DecodableDefault">DecodableDefault</a>
              </li>
            </ul>
          </li>
          <li class="nav-group-name">
            <a href="Other%20Protocols.html">Other Protocols</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="Protocols/AdvertisementDelegate.html">AdvertisementDelegate</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/Advertisements.html">Advertisements</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/Chat.html">Chat</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/ChatDelegate.html">ChatDelegate</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/ErrorReceiving.html">ErrorReceiving</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/Rating.html">Rating</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/SessionControl.html">SessionControl</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/StreamSessionDelegate.html">StreamSessionDelegate</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/Streams.html">Streams</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/StreamsDelegate.html">StreamsDelegate</a>
              </li>
            </ul>
          </li>
          <li class="nav-group-name">
            <a href="Other%20Structs.html">Other Structures</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="Structs/Message.html">Message</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/StreamLanguage.html">StreamLanguage</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/Team.html">Team</a>
              </li>
            </ul>
          </li>
        </ul>
      </nav>
      <article class="main-content">
        <section>
          <section class="section">
            
            <h1 id='ios-connecting-to-a-live-stream' class='heading'>iOS Connecting to a live stream</h1>

<p>This document describes everything related to the connection to a live stream and the workflows behind it.</p>

<p>First step should be to add the permission in your .plist file to allow background play otherwise the stream will be killed when you lock the screen or go in the background with the app.</p>
<h2 id='relevant-classes' class='heading'>Relevant classes</h2>

<ul>
<li><code><a href="Protocols/SessionControl.html">SessionControl</a></code>- the protocol to interact with playing audio and controlling the play state</li>
<li><code><a href="Protocols/StreamSessionDelegate.html">StreamSessionDelegate</a></code>- protocol to implement to receive the actual audio data and other audio session related events</li>
<li><code><a href="Enums/SessionState.html">SessionState</a></code> - enum describing the different states the session is in</li>
</ul>
<h2 id='concepts' class='heading'>Concepts</h2>

<p>The complete control of the audio session is done through the SessionControl</p>

<p>When the user stops the app (swiping it out for example) you need to call stop on the sessionControl!.</p>
<h3 id='receiving-audio' class='heading'>Receiving Audio</h3>

<p>The first step should be the creation of a class that conforms to the protocol of StreamSessionDelegate. </p>
<pre class="highlight swift"><code><span class="o">**</span>
 <span class="kt">Implement</span> <span class="n">this</span> <span class="kd">protocol</span> <span class="n">to</span> <span class="n">receive</span> <span class="n">stream</span> <span class="n">session</span> <span class="n">related</span> <span class="n">updates</span>
 <span class="o">*/</span>
<span class="kd">public</span> <span class="kd">protocol</span> <span class="kt">StreamSessionDelegate</span> <span class="p">{</span>
    <span class="cm">/**
       A change in the session state occurred
     - Parameter state: the new state
     */</span>
    <span class="kd">func</span> <span class="nf">onSessionStateUpdate</span><span class="p">(</span><span class="n">_</span> <span class="nv">state</span><span class="p">:</span> <span class="kt">SessionState</span><span class="p">)</span>
    <span class="cm">/**
     A new audio package of data is available to be played
     - Parameters:
       - data: the new data package
       - duration: the duration of audio stored in the package
     */</span>
    <span class="kd">func</span> <span class="nf">onAudioDataAvailable</span><span class="p">(</span><span class="n">_</span> <span class="nv">data</span><span class="p">:</span> <span class="kt">AVAudioPCMBuffer</span><span class="p">,</span> <span class="n">_</span> <span class="nv">duration</span><span class="p">:</span> <span class="kt">Int</span><span class="p">)</span>
    <span class="cm">/**
     The streamer muted himself
     - Parameter stream: the stream where this change occurred
     */</span>
    <span class="kd">func</span> <span class="nf">streamerMuted</span><span class="p">(</span><span class="n">_</span> <span class="nv">stream</span><span class="p">:</span> <span class="kt">LiveStream</span><span class="p">)</span>
    <span class="cm">/**
     The streamer unmuted himself
     - Parameter stream: the stream where this happened
     */</span>
    <span class="kd">func</span> <span class="nf">streamerUnMuted</span><span class="p">(</span><span class="n">_</span> <span class="nv">stream</span><span class="p">:</span> <span class="kt">LiveStream</span><span class="p">)</span>

     <span class="cm">/**
     - We have a change in the internally stored audio data and therefore a change in the total amount of delay (in ms) available
     - Parameter delay the maximum available delay currently in ms
     */</span>
    <span class="kd">func</span> <span class="nf">onAvailableDelayChanged</span><span class="p">(</span><span class="n">_</span> <span class="nv">delay</span><span class="p">:</span> <span class="kt">Int</span><span class="p">)</span>
<span class="p">}</span>
</code></pre>

<p>The next step is to register this created class as an observer in the SessionControl to actually receive session state updates and also the audio itself.</p>
<pre class="highlight swift"><code> <span class="kt">Mycrocast</span><span class="o">.</span><span class="n">shared</span><span class="o">.</span><span class="n">sessionControl</span><span class="o">.</span><span class="nf">addObserver</span><span class="p">(</span><span class="nv">streamDelegate</span><span class="p">:</span> <span class="k">self</span><span class="p">)</span>
</code></pre>

<p>You will now receive audio updates as an AVAudioPCMBuffer that contains 960 frames, at 48000khz pcm16 mono data.</p>

<p>You are responsible for playing the audio though your preferred way yourself.</p>

<p>In the example app the StreamPlayer is responsible for playing the audio packages.</p>
<h3 id='mute-music' class='heading'>Mute music</h3>

<p>A streamer could be muted during your connection time or mute himself anytime within the current broadcast.</p>

<p>When a streamer is muted you should play the mute music, the remote URL to that file is contained in the LiveStream object.</p>

<p>After connecting check the muted flag in the LiveStream and afterwards react to the specific callbacks to changes in the mute state of the streamer.</p>
<h3 id='advertisement-within-the-stream' class='heading'>Advertisement within the stream</h3>

<p>The streamer can at anytime decide that advertisements should be played within the broadcast.</p>

<p>If you decide to actually play the advertisement, reduce the audio of the stream, or the mute music to zero during the play and increase them afterwards again.</p>
<h3 id='pause-resume' class='heading'>Pause/Resume</h3>

<p>We do not provide the functionality to actually pause a stream and later on resume at that point in time. Internally each resume/play just starts from the current live moment. If you want to provide that functionality you can implement it. You should never call pause/stop on our SDK but just reduce the volume to zero and keep storing the audio packages.</p>
<h3 id='buffering' class='heading'>Buffering</h3>

<p>During the connection to a live stream you can configure the buffering amount. That is the amount of data to collect before providing the first audio packages.
A short buffer is useful for a better user experience and to mask connectivity issues.
The higher the buffer, the higher the delay and initial wait time. A value between 1s - 5s is recommended.</p>

<p>How does it work?
We initially start collecting audio packages until we have collected enough to satisfy the configured buffer time.
(We start in the buffering state)
Afterwards we change to the playing state and start providing audio packages for playback. When chaning from buffering to playing up to 10 packages are provided as burst.</p>

<p>When the buffer is empty again (bad network for example), we start buffering again until we reached the configured value.</p>
<h3 id='delay' class='heading'>Delay</h3>

<p>You can now configure a delay so that the user can sync the audio with any potencial video source.
The general flow of the delay is as following:</p>

<ol>
<li>You configure the maximum delay that is internally stored (how much audio we internally store) during connection. 5 minutes is a good value</li>
<li>As soon as the stream is connected, we collect the audio packages and update you how much we currently have collected. (see onAvailableDelayChanged from StreamSessionDelegate)</li>
<li>If enough is collected, the user can configure a delay up to the initally configured maximum</li>
<li>Any event that occurs is also processed delayed (playing of advertisement, changing the mute state and so on)</li>
<li>If the user moves the delay and &ldquo;jumps&rdquo; over an event, the event is executed (when moving to the live moment) or undone (when moving in the past)</li>
</ol>

<p>When the user pauses/stops the stream and resumes, collection of audio needs to start again.</p>

          </section>
        </section>
        <section id="footer">
          <p>&copy; 2025 <a class="link" href="https://mycrocast.com" target="_blank" rel="external noopener">mycrocast Gmbh</a>. All rights reserved. (Last updated: 2025-09-09)</p>
          <p>Generated by <a class="link" href="https://github.com/realm/jazzy" target="_blank" rel="external noopener">jazzy ♪♫ v0.14.4</a>, a <a class="link" href="https://realm.io" target="_blank" rel="external noopener">Realm</a> project.</p>
        </section>
      </article>
    </div>
  </body>
</html>
